<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Base learner: tune hyperparameters and retrieve the best model — fit_base_learner • beethoven</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Base learner: tune hyperparameters and retrieve the best model — fit_base_learner"><meta name="description" content="Multilayer perceptron model with different configurations of
hidden units, dropout, activation, and learning rate using brulee
and tidymodels. With proper settings, users can utilize graphics
processing units (GPU) to speed up the training process."><meta property="og:description" content="Multilayer perceptron model with different configurations of
hidden units, dropout, activation, and learning rate using brulee
and tidymodels. With proper settings, users can utilize graphics
processing units (GPU) to speed up the training process."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">beethoven</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.4.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../articles/index.html">Articles</a></li>
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><a class="external-link nav-link" href="https://github.com/NIEHS/beethoven/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Base learner: tune hyperparameters and retrieve the best model</h1>
      <small class="dont-index">Source: <a href="https://github.com/NIEHS/beethoven/blob/dev/R/base_learner.R" class="external-link"><code>R/base_learner.R</code></a></small>
      <div class="d-none name"><code>fit_base_learner.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Multilayer perceptron model with different configurations of
hidden units, dropout, activation, and learning rate using brulee
and tidymodels. With proper settings, users can utilize graphics
processing units (GPU) to speed up the training process.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">fit_base_learner</span><span class="op">(</span></span>
<span>  learner <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"mlp"</span>, <span class="st">"xgb"</span>, <span class="st">"lgb"</span>, <span class="st">"elnet"</span><span class="op">)</span>,</span>
<span>  <span class="va">dt_full</span>,</span>
<span>  r_subsample <span class="op">=</span> <span class="fl">0.3</span>,</span>
<span>  model <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  folds <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>  cv_mode <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"spatiotemporal"</span>, <span class="st">"spatial"</span>, <span class="st">"temporal"</span><span class="op">)</span>,</span>
<span>  args_generate_cv <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  tune_mode <span class="op">=</span> <span class="st">"grid"</span>,</span>
<span>  tune_bayes_iter <span class="op">=</span> <span class="fl">10L</span>,</span>
<span>  tune_grid_in <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  tune_grid_size <span class="op">=</span> <span class="fl">10L</span>,</span>
<span>  learn_rate <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>  yvar <span class="op">=</span> <span class="st">"Arithmetic.Mean"</span>,</span>
<span>  xvar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">dt_sample</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  nthreads <span class="op">=</span> <span class="fl">8L</span>,</span>
<span>  trim_resamples <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  return_best <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-learner">learner<a class="anchor" aria-label="anchor" href="#arg-learner"></a></dt>
<dd><p>character(1). The base learner to be used.
Default is "mlp". Available options are "mlp", "xgb", "lgb", "elnet".</p></dd>


<dt id="arg-dt-full">dt_full<a class="anchor" aria-label="anchor" href="#arg-dt-full"></a></dt>
<dd><p>The full data table to be used for prediction.</p></dd>


<dt id="arg-r-subsample">r_subsample<a class="anchor" aria-label="anchor" href="#arg-r-subsample"></a></dt>
<dd><p>numeric(1). The proportion of rows to be used.</p></dd>


<dt id="arg-model">model<a class="anchor" aria-label="anchor" href="#arg-model"></a></dt>
<dd><p>The parsnip model object. Preferably generated from
<code>switch_model</code>.</p></dd>


<dt id="arg-folds">folds<a class="anchor" aria-label="anchor" href="#arg-folds"></a></dt>
<dd><p>integer(1). Number of cross-validation folds.
If NULL, <code>cv_mode</code> should be defined to be used in <a href="https://rsample.tidymodels.org/reference/vfold_cv.html" class="external-link">rsample::vfold_cv</a>.</p></dd>


<dt id="arg-cv-mode">cv_mode<a class="anchor" aria-label="anchor" href="#arg-cv-mode"></a></dt>
<dd><p>character(1).
Cross-validation mode. Default is "spatiotemporal".
Available options are "spatiotemporal", "spatial", "temporal".</p></dd>


<dt id="arg-args-generate-cv">args_generate_cv<a class="anchor" aria-label="anchor" href="#arg-args-generate-cv"></a></dt>
<dd><p>List of arguments to be passed to
<code>switch_generate_cv_rset</code> function.</p></dd>


<dt id="arg-tune-mode">tune_mode<a class="anchor" aria-label="anchor" href="#arg-tune-mode"></a></dt>
<dd><p>character(1). Hyperparameter tuning mode.
Default is "grid", "bayes" is acceptable.</p></dd>


<dt id="arg-tune-bayes-iter">tune_bayes_iter<a class="anchor" aria-label="anchor" href="#arg-tune-bayes-iter"></a></dt>
<dd><p>integer(1). The number of iterations for
Bayesian optimization. Default is 10. Only used when <code>tune_mode = "bayes"</code>.</p></dd>


<dt id="arg-tune-grid-in">tune_grid_in<a class="anchor" aria-label="anchor" href="#arg-tune-grid-in"></a></dt>
<dd><p>data.frame object that includes the grid for
hyperparameter tuning. <code>tune_grid_size</code> rows will be randomly picked
from this data.frame for grid search.</p></dd>


<dt id="arg-tune-grid-size">tune_grid_size<a class="anchor" aria-label="anchor" href="#arg-tune-grid-size"></a></dt>
<dd><p>integer(1). The number of grid size for hyperparameter
tuning. Default is 10. Only used when <code>tune_mode = "grid"</code>.</p></dd>


<dt id="arg-learn-rate">learn_rate<a class="anchor" aria-label="anchor" href="#arg-learn-rate"></a></dt>
<dd><p>The learning rate for the model. For branching purpose.
Default is 0.1.</p></dd>


<dt id="arg-yvar">yvar<a class="anchor" aria-label="anchor" href="#arg-yvar"></a></dt>
<dd><p>The target variable.</p></dd>


<dt id="arg-xvar">xvar<a class="anchor" aria-label="anchor" href="#arg-xvar"></a></dt>
<dd><p>The predictor variables.</p></dd>


<dt id="arg-nthreads">nthreads<a class="anchor" aria-label="anchor" href="#arg-nthreads"></a></dt>
<dd><p>integer(1). The number of threads to be used for
tuning. Default is 8L. <code>learner = "elnet"</code> will utilize the multiple
threads in <code><a href="https://future.futureverse.org/reference/multicore.html" class="external-link">future::multicore()</a></code> plan.</p></dd>


<dt id="arg-trim-resamples">trim_resamples<a class="anchor" aria-label="anchor" href="#arg-trim-resamples"></a></dt>
<dd><p>logical(1). Default is TRUE, which replaces the actual
data.frames in splits column of <code>tune_results</code> object with NA.</p></dd>


<dt id="arg-return-best">return_best<a class="anchor" aria-label="anchor" href="#arg-return-best"></a></dt>
<dd><p>logical(1). If TRUE, the best tuned model is returned.</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>Additional arguments to be passed.</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>The fitted workflow.</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>LightGBM model is fitted at the defined rate (<code>r_subsample</code>) of
the input dataset by grid or Bayesian optimization search.
With proper settings, users can utilize graphics
processing units (GPU) to speed up the training process.</p>
<p>XGBoost model is fitted at the defined rate (<code>r_subsample</code>) of
the input dataset by grid or Bayesian optimization search.
With proper settings, users can utilize graphics
processing units (GPU) to speed up the training process.</p>
<p>Elastic net model is fitted at the defined rate (<code>r_subsample</code>) of
the input dataset by grid search or Bayesian optimization.</p><ul><li><p>MLP: Hyperparameters <code>hidden_units</code>, <code>dropout</code>, <code>activation</code>,
and <code>learn_rate</code> are tuned. <code>With tune_mode = "grid"</code>,
users can modify <code>learn_rate</code> explicitly, and other hyperparameters
will be predefined (56 combinations per <code>learn_rate</code> for mlp).</p></li>
<li><p>XGBoost: Hyperparameters <code>mtry</code>, <code>ntrees</code>, and <code>learn_rate</code> are
tuned. With <code>tune_mode = "grid"</code>,
users can modify <code>learn_rate</code> explicitly, and other hyperparameters
will be predefined (30 combinations per <code>learn_rate</code>).</p></li>
<li><p>LightGBM: Hyperparameters <code>mtry</code>, <code>ntrees</code>, and <code>learn_rate</code> are
tuned. With <code>tune_mode = "grid"</code>,
users can modify <code>learn_rate</code> explicitly, and other hyperparameters
will be predefined (30 combinations per <code>learn_rate</code>).</p></li>
<li><p>Elastic net: Hyperparameters <code>mixture</code> and <code>penalty</code> are tuned.</p></li>
</ul><p>Tuning is performed based on random grid search (size = 10).</p>
    </div>
    <div class="section level2">
    <h2 id="note">Note<a class="anchor" aria-label="anchor" href="#note"></a></h2>
    <p>tune package should be 1.2.0 or higher.
brulee, xgboost, and lightgbm should be installed with GPU support.
Grid search is not activated in this function, regardless of other parts'
description.</p>
    </div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Kyle Messier, Insang Song, Eva Marques, Ranadeep Daw, Mitchell Manware, Daniel Zilber, Anisha Singh, Lara Clark, Cavin Ward-Caviness, Mariana Alifa Kassien.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>

